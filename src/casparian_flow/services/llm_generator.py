
"""
LLMGenerator: The Brain.
Implements the AIGenerator interface using a generic LLMProvider.
Handles prompt engineering and POD conversion.
"""
import json
import logging
from typing import List

from casparian_flow.services.ai_hook import AIGenerator
from casparian_flow.services.ai_types import FileProfile, SchemaProposal, PluginCode, ColumnDef, FileType
from casparian_flow.services.llm_provider import LLMProvider

logger = logging.getLogger(__name__)

class LLMGenerator(AIGenerator):
    def __init__(self, provider: LLMProvider):
        self.provider = provider
        
    def propose_schema(self, profile: FileProfile) -> SchemaProposal:
        """
        Step 1: Ask LLM to analyze the FileProfile and infer a schema.
        Output: JSON SchemaProposal
        """
        # 1. Serialize Profile to Context
        # We decode the sample bytes to string if possible for the prompt
        sample_str = "<binary_data>"
        if profile.head_sample.encoding_detected:
            try:
                # Decore 'surrogates' just in case
                sample_str = profile.head_sample.data.decode(
                    profile.head_sample.encoding_detected, errors="replace"
                )
                # Cap context
                sample_str = sample_str[:2000] 
            except Exception:
                pass
                
        system_prompt = """
You are a Senior Data Engineer. 
Your task is to analyze a file sample and propose a data schema for an ETL pipeline.
You must output ONLY valid JSON.

The Output JSON must match this structure:
{
    "file_type_inferred": "str (e.g. CSV, JSON, PARQUET, FIXED_WIDTH)",
    "target_topic": "str (suggest a clean topic name)",
    "columns": [
        {"name": "col_name", "target_type": "int|float|string|bool|datetime", "description": "optional"}
    ],
    "read_strategy": "pandas|pyarrow|json|custom",
    "reasoning": "Brief explanation of your inference"
}
"""
        user_prompt = f"""
File Path: {profile.path}
Detected Type: {profile.file_type.name}
Total Size: {profile.total_size} bytes
Sample Data (First 2kb):
```
{sample_str}
```
Metadata Hints: {profile.metadata_hints}

Analyze this file and propose a schema.
"""
        
        logger.info("Sending PROPOSE request to LLM...")
        resp_str = self.provider.chat_completion(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            json_mode=True
        )
        
        # Parse JSON
        try:
            # Attempt to extract JSON if the provider returned extra text (like Claude CLI preamble)
            json_str = self._extract_json(resp_str)
            data = json.loads(json_str)
            
            # Map to POD
            cols = []
            for c in data.get("columns", []):
                cols.append(ColumnDef(
                    name=c["name"],
                    target_type=c["target_type"],
                    description=c.get("description")
                ))
            
            return SchemaProposal(
                file_type_inferred=data.get("file_type_inferred", "UNKNOWN"),
                target_topic=data.get("target_topic", "topic_unknown"),
                columns=cols,
                read_strategy=data.get("read_strategy", "manual"),
                reasoning=data.get("reasoning", "Generated by LLM")
            )
            
        except Exception as e:
            logger.error(f"Failed to parse LLM response: {resp_str}")
            raise ValueError(f"LLM returned invalid JSON: {e}")

    def _extract_json(self, text: str) -> str:
        """
        Robustly extract the largest JSON block from a string.
        Needed for providers that output preamble/postscript even in JSON mode.
        """
        text = text.strip()
        # If it looks like JSON, return it
        if text.startswith("{") and text.endswith("}"):
            return text
            
        # Regex to find JSON block
        import re
        # Look for { ... } across multiline
        match = re.search(r"(\{.*\})", text, re.DOTALL)
        if match:
             return match.group(1)
        
        # Fallback: Find first { and last }
        start = text.find("{")
        end = text.rfind("}")
        if start != -1 and end != -1:
            return text[start:end+1]
            
        return text

    def generate_plugin(self, proposal: SchemaProposal) -> PluginCode:
        """
        Step 2: Ask LLM to write the Python Plugin Code used the APPROVED proposal.
        """
        
        system_prompt = """
You are a Python Expert specializing in Data Engineering.
Write a Casparian Flow Plugin (Sidecar) to process the described data.

Rules:
1. You MUST define a class named `Handler(BasePlugin)`.
2. You MUST implement `execute(self, file_path: str)`.
3. You MUST yield `pyarrow.Table` or `pandas.DataFrame` chunks, OR call `self.publish(topic, batch)`.
4. PREFER `yield` for simplicity.
5. PREFER `pyarrow` engine for CSV/Parquet for performance (Zero-Copy).
6. Output ONLY the Python code. No markdown fences if possible, or minimal markdown.
"""
    
        # Serialize proposal for context
        schema_desc = f"""
Goal: Read format '{proposal.file_type_inferred}' using strategy '{proposal.read_strategy}'.
Target Topic: '{proposal.target_topic}'
Columns:
"""
        for c in proposal.columns:
            schema_desc += f"- {c.name} ({c.target_type}): {c.description}\n"
            
        user_prompt = f"""
{schema_desc}

Reasoning: {proposal.reasoning}

Write the complete 'handler.py' code.
Imports available: pandas, pyarrow, json, csv, casparian_flow.sdk.
"""
        logger.info("Sending GENERATE request to LLM...")
        code_str = self.provider.chat_completion(
             messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            json_mode=False
        )
        
        # Cleanup markdown fences if present
        if code_str.strip().startswith("```python"):
            code_str = code_str.split("```python")[1].split("```")[0].strip()
        elif code_str.strip().startswith("```"):
             code_str = code_str.split("```")[1].split("```")[0].strip()
             
        return PluginCode(
            filename=f"generated_{proposal.target_topic}.py",
            source_code=code_str,
            imports=[], # We don't parse imports here, just raw code
            entry_point="Handler"
        )
        
